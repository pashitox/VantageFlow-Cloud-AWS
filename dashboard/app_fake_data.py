import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import random

# ConfiguraciÃ³n de pÃ¡gina
st.set_page_config(
    page_title="VantageFlow IoT Dashboard",
    page_icon="ğŸ“Š",
    layout="wide"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 2rem;
        padding: 1rem;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #667eea;
        margin-bottom: 1rem;
    }
    .tech-badge {
        background: #e9ecef;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        display: inline-block;
        margin: 0.2rem;
    }
</style>
""", unsafe_allow_html=True)

# TÃ­tulo principal con logo
st.markdown("""
<div class="main-header">
    ğŸš€ VantageFlow - IoT Data Pipeline Dashboard
    <br>
    <small style="font-size: 1rem; opacity: 0.9;">Pipeline Serverless en AWS - Proyecto Portfolio</small>
</div>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/873/873107.png", width=80)
    st.markdown("## âš™ï¸ ConfiguraciÃ³n")
    
    demo_mode = st.selectbox("Modo de datos:", ["Datos de Ejemplo", "SimulaciÃ³n en Tiempo Real"])
    
    if demo_mode == "SimulaciÃ³n en Tiempo Real":
        auto_refresh = st.checkbox("ğŸ”„ Auto-refresh", value=True)
        refresh_rate = st.slider("Frecuencia (s)", 5, 60, 10)
    else:
        auto_refresh = False
    
    st.markdown("---")
    st.markdown("## ğŸ“Š Filtros")
    num_devices = st.slider("NÃºmero de dispositivos", 3, 15, 8)
    anomaly_rate = st.slider("Tasa de anomalÃ­as (%)", 5, 50, 20)
    
    st.markdown("---")
    st.markdown("## ğŸ”— Enlaces")
    if st.button("ğŸŒ Ver en AWS Console"):
        st.info("En producciÃ³n: https://console.aws.amazon.com")
    if st.button("ğŸ’¾ CÃ³digo en GitHub"):
        st.info("https://github.com/tu-usuario/vantageflow")

# Generar datos de ejemplo
@st.cache_data
def generate_sample_data(num_devices=8, anomaly_rate=20):
    """Genera datos de ejemplo para el dashboard"""
    
    # Datos Gold (estadÃ­sticas por dispositivo)
    devices = [f"DEV-{str(i).zfill(3)}" for i in range(1, num_devices + 1)]
    device_types = ['temperature_sensor', 'humidity_sensor', 'pressure_sensor', 'vibration_sensor']
    
    gold_data = []
    for device in devices:
        readings = random.randint(100, 1000)
        avg_value = random.uniform(20, 80)
        anomaly_pct = random.uniform(0, anomaly_rate)
        
        gold_data.append({
            'device_id': device,
            'device_type': random.choice(device_types),
            'location': random.choice(['FABRICA-A', 'FABRICA-B', 'ALMACEN', 'OFICINA']),
            'total_readings': readings,
            'avg_value': round(avg_value, 2),
            'min_value': round(avg_value * 0.7, 2),
            'max_value': round(avg_value * 1.3, 2),
            'anomaly_count': int(readings * (anomaly_pct / 100)),
            'anomaly_percentage': round(anomaly_pct, 1)
        })
    
    df_gold = pd.DataFrame(gold_data)
    
    # MÃ©tricas del pipeline
    pipeline_metrics = {
        'bronze': random.randint(10, 30),
        'silver': random.randint(8, 25),
        'gold': random.randint(5, 15),
        'anomalies': random.randint(2, 10)
    }
    
    # Timeline de procesamiento
    timeline = []
    now = datetime.now()
    for i in range(24):
        hour = (now - timedelta(hours=i)).strftime('%H:00')
        records = random.randint(500, 5000)
        timeline.append({
            'hora': hour,
            'registros_procesados': records,
            'anomalias': int(records * (anomaly_rate / 100))
        })
    
    df_timeline = pd.DataFrame(timeline[::-1])
    
    return df_gold, pipeline_metrics, df_timeline

# Obtener datos
df_gold, pipeline_metrics, df_timeline = generate_sample_data(num_devices, anomaly_rate)

# SECCIÃ“N 1: KPIs DEL PIPELINE
st.markdown("## ğŸ“ˆ KPIs del Pipeline Data Lake")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric(
        label="ğŸ“ BRONZE",
        value=pipeline_metrics['bronze'],
        delta="+2 hoy",
        help="Datos crudos en S3"
    )
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric(
        label="ğŸ”„ SILVER",
        value=pipeline_metrics['silver'],
        delta="+1 hoy",
        help="Datos limpios y validados"
    )
    st.markdown('</div>', unsafe_allow_html=True)

with col3:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric(
        label="ğŸ† GOLD",
        value=pipeline_metrics['gold'],
        delta="+1 hoy",
        help="Datos agregados para anÃ¡lisis"
    )
    st.markdown('</div>', unsafe_allow_html=True)

with col4:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.metric(
        label="âš ï¸ ANOMALIES",
        value=pipeline_metrics['anomalies'],
        delta=f"+{int(pipeline_metrics['anomalies']*0.3)} hoy",
        help="Datos sospechosos detectados"
    )
    st.markdown('</div>', unsafe_allow_html=True)

# SECCIÃ“N 2: DATOS GOLD
st.markdown("## ğŸ“Š Datos Gold - Resumen por Dispositivo")

tab1, tab2, tab3 = st.tabs(["ğŸ“‹ Tabla de Datos", "ğŸ“ˆ Visualizaciones", "ğŸ“± Dispositivos CrÃ­ticos"])

with tab1:
    # Mostrar tabla con estilo
    styled_df = df_gold.style.background_gradient(
        subset=['anomaly_percentage'], 
        cmap='RdYlGn_r'
    ).format({
        'avg_value': '{:.1f}Â°C',
        'anomaly_percentage': '{:.1f}%',
        'total_readings': '{:,}'
    })
    
    st.dataframe(styled_df, use_container_width=True, height=400)
    
    # EstadÃ­sticas resumen
    total_readings = df_gold['total_readings'].sum()
    avg_anomaly = df_gold['anomaly_percentage'].mean()
    critical_devices = df_gold[df_gold['anomaly_percentage'] > 30].shape[0]
    
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    col_stat1.metric("ğŸ“– Total Lecturas", f"{total_readings:,}")
    col_stat2.metric("ğŸ“Š AnomalÃ­a Promedio", f"{avg_anomaly:.1f}%")
    col_stat3.metric("ğŸš¨ Dispositivos CrÃ­ticos", critical_devices)

with tab2:
    col_chart1, col_chart2 = st.columns(2)
    
    with col_chart1:
        # GrÃ¡fico de barras - AnomalÃ­as por dispositivo
        fig1 = px.bar(
            df_gold.sort_values('anomaly_percentage', ascending=False).head(10),
            x='device_id',
            y='anomaly_percentage',
            color='anomaly_percentage',
            color_continuous_scale='RdYlGn_r',
            title='Top 10 Dispositivos con MÃ¡s AnomalÃ­as',
            labels={'anomaly_percentage': '% AnomalÃ­as', 'device_id': 'Dispositivo'}
        )
        fig1.update_layout(height=400)
        st.plotly_chart(fig1, use_container_width=True)
    
    with col_chart2:
        # GrÃ¡fico de dispersiÃ³n
        fig2 = px.scatter(
            df_gold,
            x='avg_value',
            y='anomaly_percentage',
            size='total_readings',
            color='device_type',
            hover_name='device_id',
            title='RelaciÃ³n: Valor Promedio vs AnomalÃ­as',
            labels={'avg_value': 'Valor Promedio', 'anomaly_percentage': '% AnomalÃ­as'}
        )
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)
    
    # Timeline de procesamiento
    st.markdown("### ğŸ“… Actividad Reciente (Ãšltimas 24h)")
    fig3 = px.line(
        df_timeline,
        x='hora',
        y=['registros_procesados', 'anomalias'],
        title='Registros Procesados por Hora',
        markers=True
    )
    st.plotly_chart(fig3, use_container_width=True)

with tab3:
    # Dispositivos crÃ­ticos
    critical_df = df_gold[df_gold['anomaly_percentage'] > 30].sort_values('anomaly_percentage', ascending=False)
    
    if not critical_df.empty:
        st.warning(f"ğŸš¨ Se detectaron {len(critical_df)} dispositivos con anomalÃ­as > 30%")
        
        for _, row in critical_df.iterrows():
            with st.container():
                col_alert1, col_alert2, col_alert3 = st.columns([2, 2, 1])
                
                with col_alert1:
                    st.markdown(f"**{row['device_id']}**")
                    st.caption(f"{row['device_type']} â€¢ {row['location']}")
                
                with col_alert2:
                    st.progress(row['anomaly_percentage']/100, 
                               text=f"AnomalÃ­as: {row['anomaly_percentage']}%")
                
                with col_alert3:
                    st.metric("Lecturas", row['total_readings'])
            
            st.divider()
    else:
        st.success("âœ… Todos los dispositivos dentro de parÃ¡metros normales")

# SECCIÃ“N 3: ARQUITECTURA DEL SISTEMA
st.markdown("## ğŸ—ï¸ Arquitectura del Sistema")

col_arch1, col_arch2 = st.columns([3, 2])

with col_arch1:
    st.markdown("""
    ### Data Lake en AWS - 4 Capas
    
    ```mermaid
    graph LR
        A[ğŸ“¥ Dispositivos IoT] --> B[ğŸŸ¤ BRONZE<br/>S3 Raw Data]
        B --> C[âšª SILVER<br/>Lambda Processing]
        C --> D[ğŸŸ¡ GOLD<br/>S3 Aggregated]
        C --> E[ğŸ”´ ANOMALIES<br/>S3 Filtered]
        D --> F[ğŸ“Š Dashboards]
        D --> G[ğŸ¤– ML Models]
        D --> H[ğŸ“ˆ Analytics]
    ```
    
    **Flujo de datos:**
    1. **Ingesta**: Dispositivos â†’ S3 Bronze (CSV)
    2. **Procesamiento**: Lambda valida y separa anomalÃ­as
    3. **AgregaciÃ³n**: Lambda calcula estadÃ­sticas por dispositivo
    4. **Consumo**: Datos listos para BI/ML
    """)

with col_arch2:
    st.markdown("### ğŸ› ï¸ Stack TecnolÃ³gico")
    
    st.markdown('<div class="tech-badge">AWS S3</div>', unsafe_allow_html=True)
    st.caption("Data Lake storage")
    
    st.markdown('<div class="tech-badge">AWS Lambda</div>', unsafe_allow_html=True)
    st.caption("Serverless computing")
    
    st.markdown('<div class="tech-badge">Python 3.11</div>', unsafe_allow_html=True)
    st.caption("ETL processing")
    
    st.markdown('<div class="tech-badge">Terraform</div>', unsafe_allow_html=True)
    st.caption("Infrastructure as Code")
    
    st.markdown('<div class="tech-badge">Streamlit</div>', unsafe_allow_html=True)
    st.caption("Dashboard visualization")
    
    st.markdown('<div class="tech-badge">Plotly</div>', unsafe_allow_html=True)
    st.caption("Interactive charts")
    
    st.markdown("### ğŸ’° OptimizaciÃ³n de Costos")
    st.metric("Costo mensual estimado", "$5-10", "-85% vs tradicional")
    st.caption("Free Tier + pay-per-use")

# SECCIÃ“N 4: PARA TU PORTFOLIO
st.markdown("## ğŸ¯ Para Tu Portfolio")

expander = st.expander("ğŸ“ Â¿CÃ³mo explicar este proyecto en entrevistas?", expanded=False)
with expander:
    st.markdown("""
    **Problema:** Procesar datos IoT en tiempo real con escalabilidad y bajo costo
    
    **SoluciÃ³n:** Pipeline serverless en AWS con arquitectura Data Lake moderna
    
    **TecnologÃ­as:** AWS (S3, Lambda, CloudWatch), Python, Terraform
    
    **Resultados:**
    - âœ… **Performance**: 1000+ registros/segundo
    - âœ… **Costo**: $5-10/mes (optimizado)
    - âœ… **Disponibilidad**: 99.9% (serverless)
    - âœ… **Mantenimiento**: Cero (fully managed)
    
    **Demo rÃ¡pida:**
    ```bash
    # Subir datos
    aws s3 cp datos.csv s3://bucket/bronze/
    
    # Ver procesamiento automÃ¡tico
    # (30 segundos despuÃ©s)
    
    # Consultar resultados
    aws s3 ls s3://bucket/gold/
    ```
    """)

# Footer profesional
st.markdown("---")

footer_col1, footer_col2, footer_col3 = st.columns(3)

with footer_col1:
    st.markdown("**ğŸ“… Ãšltima actualizaciÃ³n**")
    st.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

with footer_col2:
    st.markdown("**ğŸ”— Enlaces del proyecto**")
    st.markdown("[GitHub](https://github.com) â€¢ [LinkedIn](https://linkedin.com)")

with footer_col3:
    st.markdown("**ğŸš€ VantageFlow Cloud AWS**")
    st.markdown("Data Pipeline Serverless para IoT")

# Auto-refresh si estÃ¡ activado
if auto_refresh and demo_mode == "SimulaciÃ³n en Tiempo Real":
    time.sleep(refresh_rate)
    st.rerun()
